{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import truncnorm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_interval = 7\n",
    "geo_granularity = 'state'\n",
    "time_interval = datetime.timedelta(days = day_interval)\n",
    "start_date = datetime.date(2020, 3, 23)\n",
    "date = start_date\n",
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "while date <= datetime.date(2020, 10, 17):\n",
    "    url = 'https://raw.githubusercontent.com/stuartlynn/census_2020_response_rates/master/data/raw/' + str(\n",
    "        date) + '.csv'\n",
    "    print(str(date))\n",
    "    try:\n",
    "        df = pd.read_csv(url, error_bad_lines=False)\n",
    "    except:\n",
    "        date += time_interval\n",
    "        continue\n",
    "    subset = df[[\"CRRALL\", \"CRRINT\", \"DRRALL\", \"DRRINT\", \"state\", \"RESP_DATE\", \"county\", \"tract\"]]\n",
    "    averages = subset.groupby(geo_granularity)['CRRALL'].mean()\n",
    "    if len(results) == 0:\n",
    "        results = results.append(pd.Series(0, index=averages.keys()), ignore_index=True)\n",
    "    results = results.append(averages)\n",
    "    date += time_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab geo information\n",
    "geo_information = pd.read_csv('data/states.csv')\n",
    "social_indicators = pd.read_csv('data/Social_Indicators.csv')\n",
    "economic_indicators = pd.read_csv(\"data/Economic_Indicators.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_information[\"GEO_ID\"] = geo_information[\"GEO_ID\"].apply(lambda x: x[-2:])\n",
    "\n",
    "social_indicators_cleaned = social_indicators[[\"NAME\", \"GEO_ID\",\"DP02_0001E\", \"DP02_0068PE\", \"DP02_0113PE\", \"DP02_0153PE\"]]\n",
    "new_header = social_indicators_cleaned.iloc[0] #grab the first row for the header\n",
    "social_indicators_cleaned = social_indicators_cleaned[1:] #take the data less the header row\n",
    "social_indicators_cleaned.columns = new_header #set the header row as the df header\n",
    "\n",
    "economic_indicators_cleaned = economic_indicators[[\"NAME\", \"GEO_ID\", \"DP03_0062E\", \"DP03_0119PE\"]]\n",
    "new_header = economic_indicators_cleaned.iloc[0] #grab the first row for the header\n",
    "economic_indicators_cleaned = economic_indicators_cleaned[1:] #take the data less the header row\n",
    "economic_indicators_cleaned.columns = new_header #set the header row as the df header\n",
    "\n",
    "indicators = pd.merge(economic_indicators_cleaned, social_indicators_cleaned, on = ['Geographic Area Name', \"id\"])\n",
    "indicators['id'] = indicators['id'].apply(lambda x: x[-2:])\n",
    "indicators = indicators.query('id != \"US\"')\n",
    "indicators['id'] = indicators['id'].astype(int)\n",
    "\n",
    "for col in list(indicators):\n",
    "    if col != 'id' and col != 'Geographic Area Name':\n",
    "        indicators[col] = indicators[col].astype(float)\n",
    "\n",
    "indicators.to_csv('data/indicators.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['id'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = []\n",
    "with open('data/distributions.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"state\", \"mu1\", \"std1\", \"mu2\", \"std2\"])\n",
    "    for geo in results.keys():\n",
    "        dict_results = {}\n",
    "        geo_result = results[geo]\n",
    "        differences = [j - i for i, j in zip(geo_result[: -1], geo_result[1 :])] \n",
    "        dist_1 = differences[:7]\n",
    "        dist_2 = differences[7:]\n",
    "        \n",
    "        mu1, std1 = norm.fit(dist_1)\n",
    "        a1, b1 = (0 - mu1) / std1, (100 - mu1) / std1\n",
    "        params1 = truncnorm.fit(dist_1, fa=a, fb=b)\n",
    "        mu1, std1 = params1[2], params1[3]\n",
    "        \n",
    "        mu2, std2 = norm.fit(dist_2)\n",
    "        a2, b2 = (0 - mu2) / std2, (100 - mu2) / std2\n",
    "        params2 = truncnorm.fit(dist_2, fa=a2, fb=b2)\n",
    "        mu2, std2 = params2[2], params2[3]\n",
    "\n",
    "        writer.writerow([geo, mu1, std1, mu2, std2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = [j - i for i, j in zip(state_1[: -1], state_1[1 :])] \n",
    "print(len(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(mu, std, dist, a, b, color, filename):\n",
    "    plt.hist(dist, bins=20, density=True, alpha=0.6, color=color)\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    p = truncnorm.pdf(x, a, b, mu, std)\n",
    "    plt.plot(x, p, color, linewidth=2)\n",
    "    title = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Reponse Rate Increases\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Everything below this point is just to test / experiments.\n",
    "\n",
    "dist_1 = differences[:7]\n",
    "dist_2 = differences[7:]\n",
    "\n",
    "#first 7 weeks\n",
    "mu1, std1 = norm.fit(dist_1)\n",
    "a1, b1 = (0 - mu1) / std1, (100 - mu1) / std1\n",
    "params1 = truncnorm.fit(dist_1, fa=a, fb=b)\n",
    "plot_dist(mu1, std1, dist_1, a1, b1, '#ababab', \"Distribution Plots/first_7\")\n",
    "\n",
    "#last 21 weeks\n",
    "mu2, std2 = norm.fit(dist_2)\n",
    "a2, b2 = (0 - mu2) / std2, (100 - mu2) / std2\n",
    "params2 = truncnorm.fit(dist_2, fa=a2, fb=b2)\n",
    "plot_dist(mu2, std2, dist_2, a2, b2, '#000000', \"Distribution Plots/last_21\")\n",
    "\n",
    "mu, std = norm.fit(differences)\n",
    "a, b = (0 - mu) / std, (100 - mu) / std\n",
    "plot_dist(mu, std, differences, a, b, 'k', \"Distribution Plots/all_weeks\")\n",
    "\n",
    "\n",
    "\n",
    "# Plot the PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.hist([dist_1, dist_2], bins=20, density=True, stacked=True, alpha=0.5, color=['#ababab', '#000000'])\n",
    "#   plt.hist(dist_1, bins=10, density=True, stacked=True, alpha=0.2, color='b')\n",
    "#   plt.hist(dist_2, bins=10, density=True, stacked=True, alpha=0.2, color='r')\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 1000)\n",
    "    p1 = truncnorm.pdf(x, a1, b1, mu1, std1)\n",
    "    p2 = truncnorm.pdf(x, a2, b2, mu2, std2)\n",
    "    plt.plot(x, p1, '#ababab', linewidth=2, label = \"First 7 Weeks Truncated Fit\")\n",
    "    plt.plot(x, p2, '#000000', linewidth=2, label = \"Last 21 Weeks Truncated Fit\")\n",
    "    plt.xlabel(\"Reponse Rate Increases\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    plt.legend()\n",
    "    plt.savefig('Distribution Plots/two_distributions.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fit(data, degree):\n",
    "    x = list(range(len(data)))\n",
    "    fit = np.polyfit(x, data, deg=degree)\n",
    "    print(\"completed\")\n",
    "    return fit, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit(x, fit, data):\n",
    "    plt.xlabel('Week Since Start')\n",
    "    plt.ylabel('Cumulative Response')\n",
    "    p = np.poly1d(fit)\n",
    "    plt.plot(x, p(x))\n",
    "    plt.scatter(x,data)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below was my attempt to fit kernelized linear regressions (it works but the fit's will go negative \n",
    "# so not very good for our purposes)\n",
    "# state_1 = results[1]\n",
    "# print(state_1)\n",
    "# fit, x = get_fit(state_1, 2)\n",
    "# plot_fit(x, fit, state_1)\n",
    "\n",
    "x = np.asarray(range(len(differences)))\n",
    "new_col = np.reshape(np.log(x, where=x>0.1), (x.shape[0],1))\n",
    "x = sm.add_constant(x)\n",
    "X = np.append(x, new_col, 1)\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_fit, x = get_fit(differences, degree=2)\n",
    "plot_fit(x, diff_fit, differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sm.OLS(differences, X).fit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary())\n",
    "fig = sm.graphics.plot_fit(results, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/indicators.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
